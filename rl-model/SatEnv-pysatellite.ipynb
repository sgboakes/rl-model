{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "516a7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jan  20 13:29:40 2022\n",
    "\n",
    "@author: sgboakes\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pysatellite import Transformations, Functions, Filters\n",
    "import pysatellite.config as cfg\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    plt.close('all')\n",
    "    # ~~~~ Variables\n",
    "\n",
    "    sin = np.sin\n",
    "    cos = np.cos\n",
    "    pi = np.float64(np.pi)\n",
    "\n",
    "    sensLat = np.float64(28.300697)\n",
    "    sensLon = np.float64(-16.509675)\n",
    "    sensAlt = np.float64(2390)\n",
    "    sensLLA = np.array([[sensLat * pi / 180], [sensLon * pi / 180], [sensAlt]], dtype='float64')\n",
    "    # sensLLA = np.array([[pi/2], [0], [1000]], dtype='float64')\n",
    "    sensECEF = Transformations.LLAtoECEF(sensLLA)\n",
    "    sensECEF.shape = (3, 1)\n",
    "\n",
    "    simLength = cfg.simLength\n",
    "    simLength = 20\n",
    "    stepLength = cfg.stepLength\n",
    "\n",
    "    mu = cfg.mu\n",
    "\n",
    "    trans_earth = True\n",
    "\n",
    "    # ~~~~ Satellite Conversion\n",
    "\n",
    "    # Define sat pos in ECI and convert to AER\n",
    "    # radArr: radii for each sat metres\n",
    "    # omegaArr: orbital rate for each sat rad/s\n",
    "    # thetaArr: inclination angle for each sat rad\n",
    "    # kArr: normal vector for each sat metres\n",
    "\n",
    "    radArr = np.array([7e6, 7e6, 7e6, 7e6], dtype='float64')\n",
    "\n",
    "    omegaArr = 1 / np.sqrt(radArr ** 3 / mu)\n",
    "\n",
    "    thetaArr = np.array([[0.0], [0.1], [0.2], [0.3]], dtype='float64')\n",
    "\n",
    "    kArr = np.array([[0, 0, 0],\n",
    "                     [0, 0, 1],\n",
    "                     [1 / np.sqrt(2), 1 / np.sqrt(2), 0],\n",
    "                     [1 / np.sqrt(3), 1 / np.sqrt(3), 1 / np.sqrt(3)]],\n",
    "                    dtype='float64')\n",
    "\n",
    "    num_sats = len(radArr)\n",
    "\n",
    "    # Make data structures\n",
    "    satECI = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    satAER = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        for j in range(simLength):\n",
    "            v = np.array([[radArr[i] * sin(omegaArr[i] * (j + 1) * stepLength)],\n",
    "                          [0],\n",
    "                          [radArr[i] * cos(omegaArr[i] * (j + 1) * stepLength)]], dtype='float64')\n",
    "\n",
    "            satECI[c][:, j] = (v @ cos(thetaArr[i])) + (np.cross(kArr[i, :].T, v.T) * sin(thetaArr[i])) + (\n",
    "                        kArr[i, :].T * np.dot(kArr[i, :].T, v) * (1 - cos(thetaArr[i])))\n",
    "\n",
    "            satAER[c][:, j:j + 1] = Transformations.ECItoAER(satECI[c][:, j], stepLength, j + 1, sensECEF, sensLLA[0],\n",
    "                                                             sensLLA[1])\n",
    "\n",
    "            if not trans_earth:\n",
    "                if satAER[c][1, j] < 0:\n",
    "                    satAER[c][:, j:j + 1] = np.array([[np.nan], [np.nan], [np.nan]])\n",
    "\n",
    "        if np.isnan(satAER[c]).all():\n",
    "            print('Satellite {s} is not observable'.format(s=c))\n",
    "\n",
    "    # Add small deviations for measurements\n",
    "    # Using calculated max measurement deviations for LT:\n",
    "    # Based on 0.15\"/pixel, sat size = 2m, max range = 1.38e7\n",
    "    # sigma = 1/2 * 0.15\" for it to be definitely on that pixel\n",
    "    # Add angle devs to Az/Elev, and range devs to Range\n",
    "\n",
    "    angMeasDev, rangeMeasDev = 1e-6, 20\n",
    "\n",
    "    satAERMes = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        satAERMes[c][0, :] = satAER[c][0, :] + (angMeasDev * np.random.randn(1, simLength))\n",
    "        satAERMes[c][1, :] = satAER[c][1, :] + (angMeasDev * np.random.randn(1, simLength))\n",
    "        satAERMes[c][2, :] = satAER[c][2, :] + (rangeMeasDev * np.random.randn(1, simLength))\n",
    "\n",
    "    satECIMes = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        for j in range(simLength):\n",
    "            satECIMes[c][:, j:j + 1] = Transformations.AERtoECI(satAERMes[c][:, j], stepLength, j+1, sensECEF,\n",
    "                                                                sensLLA[0], sensLLA[1])\n",
    "\n",
    "    satState = {chr(i + 97): np.zeros((6, 1)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        for j in range(simLength):\n",
    "            if np.all(np.isnan(satECIMes[c][:, j])):\n",
    "                continue\n",
    "            else:\n",
    "                satState[c][0:3] = np.reshape(satECIMes[c][:, j], (3, 1))\n",
    "                break\n",
    "\n",
    "    # Process noise\n",
    "    stdAng = np.float64(1e-5)\n",
    "    coefA = np.float64(0.25 * stepLength ** 4.0 * stdAng ** 2.0)\n",
    "    coefB = np.float64(stepLength ** 2.0 * stdAng ** 2.0)\n",
    "    coefC = np.float64(0.5 * stepLength ** 3.0 * stdAng ** 2.0)\n",
    "\n",
    "    procNoise = np.array([[coefA, 0, 0, coefC, 0, 0],\n",
    "                          [0, coefA, 0, 0, coefC, 0],\n",
    "                          [0, 0, coefA, 0, 0, coefC],\n",
    "                          [coefC, 0, 0, coefB, 0, 0],\n",
    "                          [0, coefC, 0, 0, coefB, 0],\n",
    "                          [0, 0, coefC, 0, 0, coefB]],\n",
    "                         dtype='float64')\n",
    "\n",
    "    covState = {chr(i + 97): np.zeros((6, 6)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        covState[c] = np.float64(1e10) * np.identity(6)\n",
    "\n",
    "    covAER = np.array([[(angMeasDev * 180 / pi) ** 2, 0, 0],\n",
    "                       [0, (angMeasDev * 180 / pi) ** 2, 0],\n",
    "                       [0, 0, rangeMeasDev ** 2]],\n",
    "                      dtype='float64')\n",
    "\n",
    "    measureMatrix = np.append(np.identity(3), np.zeros((3, 3)), axis=1)\n",
    "\n",
    "    \n",
    "    # ~~~~~~ CHECK\n",
    "    totalStates = {chr(i + 97): np.zeros((6, simLength)) for i in range(num_sats)}\n",
    "    diffState = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    err_X_ECI = {chr(i + 97): np.zeros(simLength) for i in range(num_sats)}\n",
    "    err_Y_ECI = {chr(i + 97): np.zeros(simLength) for i in range(num_sats)}\n",
    "    err_Z_ECI = {chr(i + 97): np.zeros(simLength) for i in range(num_sats)}\n",
    "\n",
    "    # ~~~~~ Using EKF\n",
    "\n",
    "    delta = 1e-6\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        mesCheck = False\n",
    "        for j in range(simLength):\n",
    "            while not mesCheck:\n",
    "                if np.all(np.isnan(satECIMes[c][:, j])):\n",
    "                    break\n",
    "                else:\n",
    "                    mesCheck = True\n",
    "                    break\n",
    "\n",
    "            if not mesCheck:\n",
    "                continue\n",
    "\n",
    "            func_params = {\n",
    "                \"stepLength\": stepLength,\n",
    "                \"count\": j + 1,\n",
    "                \"sensECEF\": sensECEF,\n",
    "                \"sensLLA[0]\": sensLLA[0],\n",
    "                \"sensLLA[1]\": sensLLA[1]\n",
    "            }\n",
    "\n",
    "            jacobian = Functions.jacobian_finder(\"AERtoECI\", np.reshape(satAERMes[c][:, j], (3, 1)), func_params, delta)\n",
    "\n",
    "            # covECI = np.matmul(np.matmul(jacobian, covAER), jacobian.T)\n",
    "            covECI = jacobian @ covAER @ jacobian.T\n",
    "\n",
    "            stateTransMatrix = Functions.jacobian_finder(\"kepler\", satState[c], [], delta)\n",
    "\n",
    "            satState[c], covState[c] = Filters.EKF_ECI(satState[c], covState[c], satECIMes[c][:, j], stateTransMatrix,\n",
    "                                                       measureMatrix, covECI, procNoise)\n",
    "\n",
    "            totalStates[c][:, j] = np.reshape(satState[c], 6)\n",
    "            err_X_ECI[c][j] = (np.sqrt(np.abs(covState[c][0, 0])))\n",
    "            err_Y_ECI[c][j] = (np.sqrt(np.abs(covState[c][1, 1])))\n",
    "            err_Z_ECI[c][j] = (np.sqrt(np.abs(covState[c][2, 2])))\n",
    "            diffState[c][:, j] = totalStates[c][0:3, j] - satECI[c][:, j]\n",
    "            # print(satState[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "307f0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "# import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import PIL.Image\n",
    "# import pyvirtualdisplay\n",
    "import reverb\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1685775",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f608313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_episodes: 5 num_steps: 100\n",
      "avg_length 20.0 avg_reward: 11.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array([0., 0., 0., 0.], dtype=float32),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0, dtype=int32)})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import int32, float32\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "\n",
    "class PyEnvironment(object):\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Return initial_time_step.\"\"\"\n",
    "        self._current_time_step = self._reset()\n",
    "        return self._current_time_step\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Apply action and return new time_step.\"\"\"\n",
    "        if self._current_time_step is None:\n",
    "            return self.reset()\n",
    "        self._current_time_step = self._step(action)\n",
    "        return self._current_time_step\n",
    "\n",
    "    def current_time_step(self):\n",
    "        return self._current_time_step\n",
    "\n",
    "    def time_step_spec(self):\n",
    "        \"\"\"Return time_step_spec.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def observation_spec(self):\n",
    "        \"\"\"Return observation_spec.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def action_spec(self):\n",
    "        \"\"\"Return action_spec.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _reset(self):\n",
    "        \"\"\"Return initial_time_step.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _step(self, action):\n",
    "        \"\"\"Apply action and return new time_step.\"\"\"\n",
    "\n",
    "        \n",
    "class SatEnv(py_environment.PyEnvironment):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._num_look_spots = num_sats\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.int32, minimum=0, maximum=self._num_look_spots-1, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(4,), dtype=np.float32, minimum=0, name='observation')\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "        self._episode_duration = 0\n",
    "        self._max_episode_length = simLength\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        # self._state = 0\n",
    "        self._episode_ended = False\n",
    "        self._episode_duration = 0\n",
    "        #import pdb; pdb.set_trace()\n",
    "        return ts.restart(np.array([0.,0.,0.,0.], dtype=np.float32))\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "        reward = 0\n",
    "        if self._episode_ended:\n",
    "            # The last action ended the episode. Ignore the current action and start\n",
    "            # a new episode.\n",
    "            return self.reset()\n",
    "\n",
    "        \n",
    "        \n",
    "#         print('simlength {s} current ep {e}'.format(s=simLength,e=self._episode_duration))\n",
    "        # Radial error\n",
    "        error = [None] * num_sats\n",
    "        for i in range(num_sats):\n",
    "            c = chr(i + 97)\n",
    "            error[i] = np.sqrt(err_X_ECI[c][self._episode_duration]**2 +\n",
    "                             err_Y_ECI[c][self._episode_duration]**2 +\n",
    "                             err_Z_ECI[c][self._episode_duration]**2)\n",
    "            \n",
    "\n",
    "        # Make sure episodes don't go on forever.\n",
    "        if action == error.index(max(error)):\n",
    "            reward = 1\n",
    "        elif action == error.index(min(error)):\n",
    "            reward = -1\n",
    "            \n",
    "        # Using all actions\n",
    "#         sorted_error = sorted(error)\n",
    "#         if action == error.index(max(error)):\n",
    "#             reward = 4\n",
    "#         elif action == error.index(sorted_error[1]):\n",
    "#             reward = 3\n",
    "#         elif action == error.index(sorted_error[2]):\n",
    "#             reward = 2\n",
    "#         elif action == error.index(min(error)):\n",
    "#             reward = 1\n",
    "        \n",
    "\n",
    "        self._state = (self._state + 1) % self._num_look_spots\n",
    "        # self._state = dif\n",
    "        \n",
    "        # print(self._state)\n",
    "        # print(\"reward = \", reward)\n",
    "\n",
    "        self._episode_duration += 1\n",
    "        error = np.array(error, dtype=np.float32)\n",
    "\n",
    "        if self._episode_duration >= self._max_episode_length:\n",
    "            #print('here')\n",
    "            #import pdb; pdb.set_trace() # ALWAYS ON SAME LINE\n",
    "            self._episode_ended = True\n",
    "            return ts.termination(error, reward)\n",
    "        else:\n",
    "            return ts.transition(error, reward=reward, discount=1.0)\n",
    "\n",
    "\n",
    "env = SatEnv()\n",
    "utils.validate_py_environment(env, episodes=5)\n",
    "\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 5\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    episode_reward = 0\n",
    "    episode_steps = 0\n",
    "    while not time_step.is_last():\n",
    "        action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "        time_step = tf_env.step(action)\n",
    "        episode_steps += 1\n",
    "        episode_reward += time_step.reward.numpy()\n",
    "    rewards.append(episode_reward)\n",
    "    steps.append(episode_steps)\n",
    "    time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)\n",
    "\n",
    "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
    "print('avg_length', avg_length, 'avg_reward:', avg_reward)\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b30b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = env\n",
    "eval_py_env = env\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83e25429",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55e8c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "428ea7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "409c8d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics\n",
    "\n",
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7738027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/tfrecord_checkpointer.cc:150]  Initializing TFRecordCheckpointer in /tmp/tmp24qe6wsn.\n",
      "[reverb/cc/platform/tfrecord_checkpointer.cc:386] Loading latest checkpoint from /tmp/tmp24qe6wsn\n",
      "[reverb/cc/platform/default/server.cc:71] Started replay server on port 17097\n"
     ]
    }
   ],
   "source": [
    "table_name = 'uniform_table'\n",
    "replay_buffer_signature = tensor_spec.from_spec(\n",
    "      agent.collect_data_spec)\n",
    "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "    replay_buffer_signature)\n",
    "\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=replay_buffer_max_length,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "    signature=replay_buffer_signature)\n",
    "\n",
    "reverb_server = reverb.Server([table])\n",
    "\n",
    "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    local_server=reverb_server)\n",
    "\n",
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "  replay_buffer.py_client,\n",
    "  table_name,\n",
    "  sequence_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d17956e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('step_type',\n",
       " 'observation',\n",
       " 'action',\n",
       " 'policy_info',\n",
       " 'next_step_type',\n",
       " 'reward',\n",
       " 'discount')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec\n",
    "agent.collect_data_spec._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0fa335ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'discount': array(0., dtype=float32),\n",
       "  'observation': array([111.243835, 115.11721 ,  78.29011 ,  78.282936], dtype=float32),\n",
       "  'reward': array(0., dtype=float32),\n",
       "  'step_type': array(2, dtype=int32)}),\n",
       " ())"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      random_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=initial_collect_steps).run(train_py_env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "453f1996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/default/server.cc:84] Shutting down replay server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7ff80c4cf550>\n"
     ]
    }
   ],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "dataset\n",
    "\n",
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "070fbf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1000: Average Return = 8.0\n",
      "step = 2000: Average Return = 13.0\n",
      "step = 3000: Average Return = 18.0\n",
      "step = 4000: Average Return = 20.0\n",
      "step = 5000: Average Return = 13.0\n",
      "step = 6000: Average Return = 20.0\n",
      "step = 7000: Average Return = 20.0\n",
      "step = 8000: Average Return = 16.0\n",
      "step = 9000: Average Return = 20.0\n",
      "step = 10000: Average Return = 20.0\n",
      "step = 11000: Average Return = 18.0\n",
      "step = 12000: Average Return = 17.0\n",
      "step = 13000: Average Return = 18.0\n",
      "step = 14000: Average Return = 20.0\n",
      "step = 15000: Average Return = 20.0\n",
      "step = 16000: Average Return = 20.0\n",
      "step = 17000: Average Return = 20.0\n",
      "step = 18000: Average Return = 20.0\n",
      "step = 19000: Average Return = 20.0\n",
      "step = 20000: Average Return = 18.0\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step.\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "# Reset the environment.\n",
    "time_step = train_py_env.reset()\n",
    "\n",
    "# Create a driver to collect experience.\n",
    "collect_driver = py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      agent.collect_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=collect_steps_per_iteration)\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps and save to the replay buffer.\n",
    "  time_step, _ = collect_driver.run(time_step)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "#   if step % log_interval == 0:\n",
    "#     print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f9a7f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "\n",
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "# plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab19112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
