{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "516a7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jan  20 13:29:40 2022\n",
    "\n",
    "@author: sgboakes\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pysatellite import Transformations, Functions, Filters\n",
    "import pysatellite.config as cfg\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    plt.close('all')\n",
    "    # ~~~~ Variables\n",
    "\n",
    "    sin = np.sin\n",
    "    cos = np.cos\n",
    "    pi = np.float64(np.pi)\n",
    "\n",
    "    sensLat = np.float64(28.300697)\n",
    "    sensLon = np.float64(-16.509675)\n",
    "    sensAlt = np.float64(2390)\n",
    "    sensLLA = np.array([[sensLat * pi / 180], [sensLon * pi / 180], [sensAlt]], dtype='float64')\n",
    "    # sensLLA = np.array([[pi/2], [0], [1000]], dtype='float64')\n",
    "    sensECEF = Transformations.LLAtoECEF(sensLLA)\n",
    "    sensECEF.shape = (3, 1)\n",
    "\n",
    "    simLength = cfg.simLength\n",
    "    simLength = 30\n",
    "    stepLength = cfg.stepLength\n",
    "\n",
    "    mu = cfg.mu\n",
    "\n",
    "    trans_earth = True\n",
    "\n",
    "    # ~~~~ Satellite Conversion\n",
    "\n",
    "    # Define sat pos in ECI and convert to AER\n",
    "    # radArr: radii for each sat metres\n",
    "    # omegaArr: orbital rate for each sat rad/s\n",
    "    # thetaArr: inclination angle for each sat rad\n",
    "    # kArr: normal vector for each sat metres\n",
    "\n",
    "    radArr = np.array([7e6, 7e6, 7e6, 7e6], dtype='float64')\n",
    "\n",
    "    omegaArr = 1 / np.sqrt(radArr ** 3 / mu)\n",
    "\n",
    "    thetaArr = np.array([[0.0], [0.1], [0.2], [0.3]], dtype='float64')\n",
    "\n",
    "    kArr = np.array([[0, 0, 0],\n",
    "                     [0, 0, 1],\n",
    "                     [1 / np.sqrt(2), 1 / np.sqrt(2), 0],\n",
    "                     [1 / np.sqrt(3), 1 / np.sqrt(3), 1 / np.sqrt(3)]],\n",
    "                    dtype='float64')\n",
    "\n",
    "    num_sats = len(radArr)\n",
    "\n",
    "    # Make data structures\n",
    "    satECI = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    satAER = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        for j in range(simLength):\n",
    "            v = np.array([[radArr[i] * sin(omegaArr[i] * (j + 1) * stepLength)],\n",
    "                          [0],\n",
    "                          [radArr[i] * cos(omegaArr[i] * (j + 1) * stepLength)]], dtype='float64')\n",
    "\n",
    "            satECI[c][:, j] = (v @ cos(thetaArr[i])) + (np.cross(kArr[i, :].T, v.T) * sin(thetaArr[i])) + (\n",
    "                        kArr[i, :].T * np.dot(kArr[i, :].T, v) * (1 - cos(thetaArr[i])))\n",
    "\n",
    "            satAER[c][:, j:j + 1] = Transformations.ECItoAER(satECI[c][:, j], stepLength, j + 1, sensECEF, sensLLA[0],\n",
    "                                                             sensLLA[1])\n",
    "\n",
    "            if not trans_earth:\n",
    "                if satAER[c][1, j] < 0:\n",
    "                    satAER[c][:, j:j + 1] = np.array([[np.nan], [np.nan], [np.nan]])\n",
    "\n",
    "        if np.isnan(satAER[c]).all():\n",
    "            print('Satellite {s} is not observable'.format(s=c))\n",
    "\n",
    "    # Add small deviations for measurements\n",
    "    # Using calculated max measurement deviations for LT:\n",
    "    # Based on 0.15\"/pixel, sat size = 2m, max range = 1.38e7\n",
    "    # sigma = 1/2 * 0.15\" for it to be definitely on that pixel\n",
    "    # Add angle devs to Az/Elev, and range devs to Range\n",
    "\n",
    "    angMeasDev, rangeMeasDev = 1e-6, 20\n",
    "\n",
    "    satAERMes = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        satAERMes[c][0, :] = satAER[c][0, :] + (angMeasDev * np.random.randn(1, simLength))\n",
    "        satAERMes[c][1, :] = satAER[c][1, :] + (angMeasDev * np.random.randn(1, simLength))\n",
    "        satAERMes[c][2, :] = satAER[c][2, :] + (rangeMeasDev * np.random.randn(1, simLength))\n",
    "\n",
    "    satECIMes = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        for j in range(simLength):\n",
    "            satECIMes[c][:, j:j + 1] = Transformations.AERtoECI(satAERMes[c][:, j], stepLength, j+1, sensECEF,\n",
    "                                                                sensLLA[0], sensLLA[1])\n",
    "\n",
    "    satState = {chr(i + 97): np.zeros((6, 1)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        for j in range(simLength):\n",
    "            if np.all(np.isnan(satECIMes[c][:, j])):\n",
    "                continue\n",
    "            else:\n",
    "                satState[c][0:3] = np.reshape(satECIMes[c][:, j], (3, 1))\n",
    "                break\n",
    "\n",
    "    # Process noise\n",
    "    stdAng = np.float64(1e-5)\n",
    "    coefA = np.float64(0.25 * stepLength ** 4.0 * stdAng ** 2.0)\n",
    "    coefB = np.float64(stepLength ** 2.0 * stdAng ** 2.0)\n",
    "    coefC = np.float64(0.5 * stepLength ** 3.0 * stdAng ** 2.0)\n",
    "\n",
    "    procNoise = np.array([[coefA, 0, 0, coefC, 0, 0],\n",
    "                          [0, coefA, 0, 0, coefC, 0],\n",
    "                          [0, 0, coefA, 0, 0, coefC],\n",
    "                          [coefC, 0, 0, coefB, 0, 0],\n",
    "                          [0, coefC, 0, 0, coefB, 0],\n",
    "                          [0, 0, coefC, 0, 0, coefB]],\n",
    "                         dtype='float64')\n",
    "\n",
    "    covState = {chr(i + 97): np.zeros((6, 6)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        covState[c] = np.float64(1e10) * np.identity(6)\n",
    "\n",
    "    covAER = np.array([[(angMeasDev * 180 / pi) ** 2, 0, 0],\n",
    "                       [0, (angMeasDev * 180 / pi) ** 2, 0],\n",
    "                       [0, 0, rangeMeasDev ** 2]],\n",
    "                      dtype='float64')\n",
    "\n",
    "    measureMatrix = np.append(np.identity(3), np.zeros((3, 3)), axis=1)\n",
    "\n",
    "    \n",
    "    # ~~~~~~ CHECK\n",
    "    totalStates = {chr(i + 97): np.zeros((6, simLength)) for i in range(num_sats)}\n",
    "    diffState = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    err_X_ECI = {chr(i + 97): np.zeros(simLength) for i in range(num_sats)}\n",
    "    err_Y_ECI = {chr(i + 97): np.zeros(simLength) for i in range(num_sats)}\n",
    "    err_Z_ECI = {chr(i + 97): np.zeros(simLength) for i in range(num_sats)}\n",
    "\n",
    "    # ~~~~~ Using EKF\n",
    "\n",
    "    delta = 1e-6\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        mesCheck = False\n",
    "        for j in range(simLength):\n",
    "            while not mesCheck:\n",
    "                if np.all(np.isnan(satECIMes[c][:, j])):\n",
    "                    break\n",
    "                else:\n",
    "                    mesCheck = True\n",
    "                    break\n",
    "\n",
    "            if not mesCheck:\n",
    "                continue\n",
    "\n",
    "            func_params = {\n",
    "                \"stepLength\": stepLength,\n",
    "                \"count\": j + 1,\n",
    "                \"sensECEF\": sensECEF,\n",
    "                \"sensLLA[0]\": sensLLA[0],\n",
    "                \"sensLLA[1]\": sensLLA[1]\n",
    "            }\n",
    "\n",
    "            jacobian = Functions.jacobian_finder(\"AERtoECI\", np.reshape(satAERMes[c][:, j], (3, 1)), func_params, delta)\n",
    "\n",
    "            # covECI = np.matmul(np.matmul(jacobian, covAER), jacobian.T)\n",
    "            covECI = jacobian @ covAER @ jacobian.T\n",
    "\n",
    "            stateTransMatrix = Functions.jacobian_finder(\"kepler\", satState[c], [], delta)\n",
    "\n",
    "            satState[c], covState[c] = Filters.EKF_ECI(satState[c], covState[c], satECIMes[c][:, j], stateTransMatrix,\n",
    "                                                       measureMatrix, covECI, procNoise)\n",
    "\n",
    "            totalStates[c][:, j] = np.reshape(satState[c], 6)\n",
    "            err_X_ECI[c][j] = (np.sqrt(np.abs(covState[c][0, 0])))\n",
    "            err_Y_ECI[c][j] = (np.sqrt(np.abs(covState[c][1, 1])))\n",
    "            err_Z_ECI[c][j] = (np.sqrt(np.abs(covState[c][2, 2])))\n",
    "            diffState[c][:, j] = totalStates[c][0:3, j] - satECI[c][:, j]\n",
    "            # print(satState[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "307f0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "# import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import PIL.Image\n",
    "# import pyvirtualdisplay\n",
    "import reverb\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1685775",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1  # @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f608313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_episodes: 5 num_steps: 150\n",
      "avg_length 30.0 avg_reward: 16.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array([0., 0., 0., 0.], dtype=float32),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0, dtype=int32)})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import int32, float32\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "\n",
    "class PyEnvironment(object):\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Return initial_time_step.\"\"\"\n",
    "        self._current_time_step = self._reset()\n",
    "        return self._current_time_step\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Apply action and return new time_step.\"\"\"\n",
    "        if self._current_time_step is None:\n",
    "            return self.reset()\n",
    "        self._current_time_step = self._step(action)\n",
    "        return self._current_time_step\n",
    "\n",
    "    def current_time_step(self):\n",
    "        return self._current_time_step\n",
    "\n",
    "    def time_step_spec(self):\n",
    "        \"\"\"Return time_step_spec.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def observation_spec(self):\n",
    "        \"\"\"Return observation_spec.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def action_spec(self):\n",
    "        \"\"\"Return action_spec.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _reset(self):\n",
    "        \"\"\"Return initial_time_step.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _step(self, action):\n",
    "        \"\"\"Apply action and return new time_step.\"\"\"\n",
    "\n",
    "        \n",
    "class SatEnv(py_environment.PyEnvironment):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._num_look_spots = num_sats\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.int32, minimum=0, maximum=self._num_look_spots-1, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(4,), dtype=np.float32, minimum=0, name='observation')\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "        self._episode_duration = 0\n",
    "        self._max_episode_length = simLength\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        # self._state = 0\n",
    "        self._episode_ended = False\n",
    "        self._episode_duration = 0\n",
    "        #import pdb; pdb.set_trace()\n",
    "        return ts.restart(np.array([0.,0.,0.,0.], dtype=np.float32))\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "        reward = 0\n",
    "        if self._episode_ended:\n",
    "            # The last action ended the episode. Ignore the current action and start\n",
    "            # a new episode.\n",
    "            return self.reset()\n",
    "\n",
    "        \n",
    "        # ~~~~ Compare error_k to error_k+1\n",
    "        \n",
    "#         print('simlength {s} current ep {e}'.format(s=simLength,e=self._episode_duration))\n",
    "        # Radial error\n",
    "        error = [None] * num_sats\n",
    "        for i in range(num_sats):\n",
    "            c = chr(i + 97)\n",
    "            error[i] = np.sqrt(err_X_ECI[c][self._episode_duration]**2 +\n",
    "                               err_Y_ECI[c][self._episode_duration]**2 +\n",
    "                               err_Z_ECI[c][self._episode_duration]**2)\n",
    "            \n",
    "\n",
    "        # Make sure episodes don't go on forever.\n",
    "        \n",
    "        # ~~~~~~ don't use negative rewards\n",
    "        if action == error.index(max(error)):\n",
    "            reward = 1\n",
    "        elif action == error.index(min(error)):\n",
    "            reward = -1\n",
    "            \n",
    "        # Using all actions\n",
    "#         sorted_error = sorted(error)\n",
    "#         if action == error.index(max(error)):\n",
    "#             reward = 4\n",
    "#         elif action == error.index(sorted_error[1]):\n",
    "#             reward = 3\n",
    "#         elif action == error.index(sorted_error[2]):\n",
    "#             reward = 2\n",
    "#         elif action == error.index(min(error)):\n",
    "#             reward = 1\n",
    "        \n",
    "\n",
    "        self._state = (self._state + 1) % self._num_look_spots\n",
    "        # self._state = dif\n",
    "        \n",
    "        # print(self._state)\n",
    "        # print(\"reward = \", reward)\n",
    "\n",
    "        self._episode_duration += 1\n",
    "        error = np.array(error, dtype=np.float32)\n",
    "\n",
    "        if self._episode_duration >= self._max_episode_length:\n",
    "            #print('here')\n",
    "            #import pdb; pdb.set_trace() # ALWAYS ON SAME LINE\n",
    "            self._episode_ended = True\n",
    "            return ts.termination(error, reward)\n",
    "        else:\n",
    "            return ts.transition(error, reward=reward, discount=1.0)\n",
    "\n",
    "\n",
    "env = SatEnv()\n",
    "utils.validate_py_environment(env, episodes=5)\n",
    "\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 5\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    episode_reward = 0\n",
    "    episode_steps = 0\n",
    "    while not time_step.is_last():\n",
    "        action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "        time_step = tf_env.step(action)\n",
    "        episode_steps += 1\n",
    "        episode_reward += time_step.reward.numpy()\n",
    "    rewards.append(episode_reward)\n",
    "    steps.append(episode_steps)\n",
    "    time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)\n",
    "\n",
    "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
    "print('avg_length', avg_length, 'avg_reward:', avg_reward)\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b30b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = env\n",
    "eval_py_env = env\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "83e25429",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55e8c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "428ea7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "409c8d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics\n",
    "\n",
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7738027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/tfrecord_checkpointer.cc:150]  Initializing TFRecordCheckpointer in /tmp/tmpuovyb18k.\n",
      "[reverb/cc/platform/tfrecord_checkpointer.cc:386] Loading latest checkpoint from /tmp/tmpuovyb18k\n",
      "[reverb/cc/platform/default/server.cc:71] Started replay server on port 17324\n"
     ]
    }
   ],
   "source": [
    "table_name = 'uniform_table'\n",
    "replay_buffer_signature = tensor_spec.from_spec(\n",
    "      agent.collect_data_spec)\n",
    "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "    replay_buffer_signature)\n",
    "\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=replay_buffer_max_length,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "    signature=replay_buffer_signature)\n",
    "\n",
    "reverb_server = reverb.Server([table])\n",
    "\n",
    "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    local_server=reverb_server)\n",
    "\n",
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "  replay_buffer.py_client,\n",
    "  table_name,\n",
    "  sequence_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d17956e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('step_type',\n",
       " 'observation',\n",
       " 'action',\n",
       " 'policy_info',\n",
       " 'next_step_type',\n",
       " 'reward',\n",
       " 'discount')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec\n",
    "agent.collect_data_spec._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fa335ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'discount': array(1., dtype=float32),\n",
       "  'observation': array([228.12506, 229.20172, 187.29944, 177.12234], dtype=float32),\n",
       "  'reward': array(-1., dtype=float32),\n",
       "  'step_type': array(1, dtype=int32)}),\n",
       " ())"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      random_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=initial_collect_steps).run(train_py_env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "453f1996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/default/server.cc:84] Shutting down replay server\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7fa41023bdc0>\n"
     ]
    }
   ],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "dataset\n",
    "\n",
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "070fbf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (8953) so Table uniform_table is accessed directly without gRPC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1000: Average Return = 22.0\n",
      "step = 2000: Average Return = 24.0\n",
      "step = 3000: Average Return = 29.0\n",
      "step = 4000: Average Return = 0.0\n",
      "step = 5000: Average Return = 28.0\n",
      "step = 6000: Average Return = 15.0\n",
      "step = 7000: Average Return = 8.0\n",
      "step = 8000: Average Return = 4.0\n",
      "step = 9000: Average Return = -3.0\n",
      "step = 10000: Average Return = -5.0\n",
      "step = 11000: Average Return = 4.0\n",
      "step = 12000: Average Return = -4.0\n",
      "step = 13000: Average Return = 29.0\n",
      "step = 14000: Average Return = 29.0\n",
      "step = 15000: Average Return = 30.0\n",
      "step = 16000: Average Return = 30.0\n",
      "step = 17000: Average Return = 30.0\n",
      "step = 18000: Average Return = 30.0\n",
      "step = 19000: Average Return = 30.0\n",
      "step = 20000: Average Return = 30.0\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step.\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "# Reset the environment.\n",
    "time_step = train_py_env.reset()\n",
    "\n",
    "# Create a driver to collect experience.\n",
    "collect_driver = py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      agent.collect_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=collect_steps_per_iteration)\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps and save to the replay buffer.\n",
    "  time_step, _ = collect_driver.run(time_step)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "#   if step % log_interval == 0:\n",
    "#     print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2f9a7f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "\n",
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "# plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab19112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
