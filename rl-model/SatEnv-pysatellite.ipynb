{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "516a7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jan  20 13:29:40 2022\n",
    "\n",
    "@author: sgboakes\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pysatellite import Transformations, Functions, Filters\n",
    "import pysatellite.config as cfg\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    plt.close('all')\n",
    "    # ~~~~ Variables\n",
    "\n",
    "    sin = np.sin\n",
    "    cos = np.cos\n",
    "    pi = np.float64(np.pi)\n",
    "\n",
    "    sensLat = np.float64(28.300697)\n",
    "    sensLon = np.float64(-16.509675)\n",
    "    sensAlt = np.float64(2390)\n",
    "    sensLLA = np.array([[sensLat * pi / 180], [sensLon * pi / 180], [sensAlt]], dtype='float64')\n",
    "    # sensLLA = np.array([[pi/2], [0], [1000]], dtype='float64')\n",
    "    sensECEF = Transformations.LLAtoECEF(sensLLA)\n",
    "    sensECEF.shape = (3, 1)\n",
    "\n",
    "    simLength = cfg.simLength\n",
    "    stepLength = cfg.stepLength\n",
    "\n",
    "    mu = cfg.mu\n",
    "\n",
    "    trans_earth = True\n",
    "\n",
    "    # ~~~~ Satellite Conversion\n",
    "\n",
    "    # Define sat pos in ECI and convert to AER\n",
    "    # radArr: radii for each sat metres\n",
    "    # omegaArr: orbital rate for each sat rad/s\n",
    "    # thetaArr: inclination angle for each sat rad\n",
    "    # kArr: normal vector for each sat metres\n",
    "\n",
    "    radArr = np.array([7e6, 7e6, 7e6, 7e6], dtype='float64')\n",
    "\n",
    "    omegaArr = 1 / np.sqrt(radArr ** 3 / mu)\n",
    "\n",
    "    thetaArr = np.array([[0.0], [0.1], [0.2], [0.3]], dtype='float64')\n",
    "\n",
    "    kArr = np.array([[0, 0, 0],\n",
    "                     [0, 0, 1],\n",
    "                     [1 / np.sqrt(2), 1 / np.sqrt(2), 0],\n",
    "                     [1 / np.sqrt(3), 1 / np.sqrt(3), 1 / np.sqrt(3)]],\n",
    "                    dtype='float64')\n",
    "\n",
    "    num_sats = len(radArr)\n",
    "\n",
    "    # Make data structures\n",
    "    satECI = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    satAER = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        for j in range(simLength):\n",
    "            v = np.array([[radArr[i] * sin(omegaArr[i] * (j + 1) * stepLength)],\n",
    "                          [0],\n",
    "                          [radArr[i] * cos(omegaArr[i] * (j + 1) * stepLength)]], dtype='float64')\n",
    "\n",
    "            satECI[c][:, j] = (v @ cos(thetaArr[i])) + (np.cross(kArr[i, :].T, v.T) * sin(thetaArr[i])) + (\n",
    "                        kArr[i, :].T * np.dot(kArr[i, :].T, v) * (1 - cos(thetaArr[i])))\n",
    "\n",
    "            satAER[c][:, j:j + 1] = Transformations.ECItoAER(satECI[c][:, j], stepLength, j + 1, sensECEF, sensLLA[0],\n",
    "                                                             sensLLA[1])\n",
    "\n",
    "            if not trans_earth:\n",
    "                if satAER[c][1, j] < 0:\n",
    "                    satAER[c][:, j:j + 1] = np.array([[np.nan], [np.nan], [np.nan]])\n",
    "\n",
    "        if np.isnan(satAER[c]).all():\n",
    "            print('Satellite {s} is not observable'.format(s=c))\n",
    "\n",
    "    # Add small deviations for measurements\n",
    "    # Using calculated max measurement deviations for LT:\n",
    "    # Based on 0.15\"/pixel, sat size = 2m, max range = 1.38e7\n",
    "    # sigma = 1/2 * 0.15\" for it to be definitely on that pixel\n",
    "    # Add angle devs to Az/Elev, and range devs to Range\n",
    "\n",
    "    angMeasDev, rangeMeasDev = 1e-6, 20\n",
    "\n",
    "    satAERMes = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        satAERMes[c][0, :] = satAER[c][0, :] + (angMeasDev * np.random.randn(1, simLength))\n",
    "        satAERMes[c][1, :] = satAER[c][1, :] + (angMeasDev * np.random.randn(1, simLength))\n",
    "        satAERMes[c][2, :] = satAER[c][2, :] + (rangeMeasDev * np.random.randn(1, simLength))\n",
    "\n",
    "    satECIMes = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        for j in range(simLength):\n",
    "            satECIMes[c][:, j:j + 1] = Transformations.AERtoECI(satAERMes[c][:, j], stepLength, j+1, sensECEF,\n",
    "                                                                sensLLA[0], sensLLA[1])\n",
    "\n",
    "    satState = {chr(i + 97): np.zeros((6, 1)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        for j in range(simLength):\n",
    "            if np.all(np.isnan(satECIMes[c][:, j])):\n",
    "                continue\n",
    "            else:\n",
    "                satState[c][0:3] = np.reshape(satECIMes[c][:, j], (3, 1))\n",
    "                break\n",
    "\n",
    "    # Process noise\n",
    "    stdAng = np.float64(1e-5)\n",
    "    coefA = np.float64(0.25 * stepLength ** 4.0 * stdAng ** 2.0)\n",
    "    coefB = np.float64(stepLength ** 2.0 * stdAng ** 2.0)\n",
    "    coefC = np.float64(0.5 * stepLength ** 3.0 * stdAng ** 2.0)\n",
    "\n",
    "    procNoise = np.array([[coefA, 0, 0, coefC, 0, 0],\n",
    "                          [0, coefA, 0, 0, coefC, 0],\n",
    "                          [0, 0, coefA, 0, 0, coefC],\n",
    "                          [coefC, 0, 0, coefB, 0, 0],\n",
    "                          [0, coefC, 0, 0, coefB, 0],\n",
    "                          [0, 0, coefC, 0, 0, coefB]],\n",
    "                         dtype='float64')\n",
    "\n",
    "    covState = {chr(i + 97): np.zeros((6, 6)) for i in range(num_sats)}\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        covState[c] = np.float64(1e10) * np.identity(6)\n",
    "\n",
    "    covAER = np.array([[(angMeasDev * 180 / pi) ** 2, 0, 0],\n",
    "                       [0, (angMeasDev * 180 / pi) ** 2, 0],\n",
    "                       [0, 0, rangeMeasDev ** 2]],\n",
    "                      dtype='float64'\n",
    "                      )\n",
    "\n",
    "    measureMatrix = np.append(np.identity(3), np.zeros((3, 3)), axis=1)\n",
    "\n",
    "    \n",
    "    # ~~~~~~ CHECK\n",
    "    totalStates = {chr(i + 97): np.zeros((6, simLength)) for i in range(num_sats)}\n",
    "    diffState = {chr(i + 97): np.zeros((3, simLength)) for i in range(num_sats)}\n",
    "    err_X_ECI = {chr(i + 97): np.zeros(simLength) for i in range(num_sats)}\n",
    "    err_Y_ECI = {chr(i + 97): np.zeros(simLength) for i in range(num_sats)}\n",
    "    err_Z_ECI = {chr(i + 97): np.zeros(simLength) for i in range(num_sats)}\n",
    "\n",
    "    # ~~~~~ Using EKF\n",
    "\n",
    "    delta = 1e-6\n",
    "    for i in range(num_sats):\n",
    "        c = chr(i + 97)\n",
    "        mesCheck = False\n",
    "        for j in range(simLength):\n",
    "            while not mesCheck:\n",
    "                if np.all(np.isnan(satECIMes[c][:, j])):\n",
    "                    break\n",
    "                else:\n",
    "                    mesCheck = True\n",
    "                    break\n",
    "\n",
    "            if not mesCheck:\n",
    "                continue\n",
    "\n",
    "            func_params = {\n",
    "                \"stepLength\": stepLength,\n",
    "                \"count\": j + 1,\n",
    "                \"sensECEF\": sensECEF,\n",
    "                \"sensLLA[0]\": sensLLA[0],\n",
    "                \"sensLLA[1]\": sensLLA[1]\n",
    "            }\n",
    "\n",
    "            jacobian = Functions.jacobian_finder(\"AERtoECI\", np.reshape(satAERMes[c][:, j], (3, 1)), func_params, delta)\n",
    "\n",
    "            # covECI = np.matmul(np.matmul(jacobian, covAER), jacobian.T)\n",
    "            covECI = jacobian @ covAER @ jacobian.T\n",
    "\n",
    "            stateTransMatrix = Functions.jacobian_finder(\"kepler\", satState[c], [], delta)\n",
    "\n",
    "            satState[c], covState[c] = Filters.EKF_ECI(satState[c], covState[c], satECIMes[c][:, j], stateTransMatrix,\n",
    "                                                       measureMatrix, covECI, procNoise)\n",
    "\n",
    "            totalStates[c][:, j] = np.reshape(satState[c], 6)\n",
    "            err_X_ECI[c][j] = (np.sqrt(np.abs(covState[c][0, 0])))\n",
    "            err_Y_ECI[c][j] = (np.sqrt(np.abs(covState[c][1, 1])))\n",
    "            err_Z_ECI[c][j] = (np.sqrt(np.abs(covState[c][2, 2])))\n",
    "            diffState[c][:, j] = totalStates[c][0:3, j] - satECI[c][:, j]\n",
    "            # print(satState[c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "307f0244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 15:02:56.018057: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-21 15:02:56.018092: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import base64\n",
    "# import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import PIL.Image\n",
    "# import pyvirtualdisplay\n",
    "import reverb\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import py_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import sequential\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.specs import tensor_spec\n",
    "from tf_agents.utils import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1685775",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 20000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 100  # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration =   1# @param {type:\"integer\"}\n",
    "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 64  # @param {type:\"integer\"}\n",
    "learning_rate = 1e-3  # @param {type:\"number\"}\n",
    "log_interval = 200  # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 10  # @param {type:\"integer\"}\n",
    "eval_interval = 1000  # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f608313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "num_episodes: 5 num_steps: 2500\n",
      "avg_length 500.0 avg_reward: 95.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TimeStep(\n",
       "{'discount': array(1., dtype=float32),\n",
       " 'observation': array([0., 0., 0., 0.], dtype=float32),\n",
       " 'reward': array(0., dtype=float32),\n",
       " 'step_type': array(0, dtype=int32)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import int32, float32\n",
    "\n",
    "from tf_agents.environments import py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "\n",
    "\n",
    "class PyEnvironment(object):\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Return initial_time_step.\"\"\"\n",
    "        self._current_time_step = self._reset()\n",
    "        return self._current_time_step\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Apply action and return new time_step.\"\"\"\n",
    "        if self._current_time_step is None:\n",
    "            return self.reset()\n",
    "        self._current_time_step = self._step(action)\n",
    "        return self._current_time_step\n",
    "\n",
    "    def current_time_step(self):\n",
    "        return self._current_time_step\n",
    "\n",
    "    def time_step_spec(self):\n",
    "        \"\"\"Return time_step_spec.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def observation_spec(self):\n",
    "        \"\"\"Return observation_spec.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def action_spec(self):\n",
    "        \"\"\"Return action_spec.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _reset(self):\n",
    "        \"\"\"Return initial_time_step.\"\"\"\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def _step(self, action):\n",
    "        \"\"\"Apply action and return new time_step.\"\"\"\n",
    "\n",
    "        \n",
    "class SatEnv(py_environment.PyEnvironment):\n",
    "\n",
    "    def __init__(self):\n",
    "        self._num_look_spots = num_sats\n",
    "        self._action_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(), dtype=np.int32, minimum=0, maximum=self._num_look_spots, name='action')\n",
    "        self._observation_spec = array_spec.BoundedArraySpec(\n",
    "            shape=(4,), dtype=np.float32, minimum=0, name='observation')\n",
    "        self._state = 0\n",
    "        self._episode_ended = False\n",
    "        self._episode_duration = 0\n",
    "        self._max_episode_length = simLength\n",
    "\n",
    "    def action_spec(self):\n",
    "        return self._action_spec\n",
    "\n",
    "    def observation_spec(self):\n",
    "        return self._observation_spec\n",
    "\n",
    "    def _reset(self):\n",
    "        # self._state = 0\n",
    "        self._episode_ended = False\n",
    "        self._episode_duration = 0\n",
    "        #import pdb; pdb.set_trace()\n",
    "        return ts.restart(np.array([0.,0.,0.,0.], dtype=np.float32))\n",
    "\n",
    "    def _step(self, action):\n",
    "\n",
    "        reward = 0\n",
    "        if self._episode_ended:\n",
    "            # The last action ended the episode. Ignore the current action and start\n",
    "            # a new episode.\n",
    "            return self.reset()\n",
    "\n",
    "        \n",
    "        \n",
    "#         print('simlength {s} current ep {e}'.format(s=simLength,e=self._episode_duration))\n",
    "        # Radial error\n",
    "        error = [None] * num_sats\n",
    "        for i in range(num_sats):\n",
    "            c = chr(i + 97)\n",
    "            error[i] = np.sqrt(err_X_ECI[c][self._episode_duration]**2 +\n",
    "                             err_Y_ECI[c][self._episode_duration]**2 +\n",
    "                             err_Z_ECI[c][self._episode_duration]**2)\n",
    "            \n",
    "\n",
    "        # Make sure episodes don't go on forever.\n",
    "        if action == error.index(max(error)):\n",
    "            reward = 1\n",
    "\n",
    "        self._state = (self._state + 1) % self._num_look_spots\n",
    "        # self._state = dif\n",
    "        \n",
    "        # print(self._state)\n",
    "        # print(\"reward = \", reward)\n",
    "\n",
    "        self._episode_duration += 1\n",
    "        error = np.array(error, dtype=np.float32)\n",
    "\n",
    "        if self._episode_duration >= self._max_episode_length:\n",
    "            print('here')\n",
    "            #import pdb; pdb.set_trace() # ALWAYS ON SAME LINE\n",
    "            self._episode_ended = True\n",
    "            return ts.termination(error, reward)\n",
    "        else:\n",
    "            return ts.transition(error, reward=reward, discount=1.0)\n",
    "\n",
    "\n",
    "env = SatEnv()\n",
    "utils.validate_py_environment(env, episodes=5)\n",
    "\n",
    "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
    "time_step = tf_env.reset()\n",
    "rewards = []\n",
    "steps = []\n",
    "num_episodes = 5\n",
    "\n",
    "for _ in range(num_episodes):\n",
    "    episode_reward = 0\n",
    "    episode_steps = 0\n",
    "    while not time_step.is_last():\n",
    "        action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
    "        time_step = tf_env.step(action)\n",
    "        episode_steps += 1\n",
    "        episode_reward += time_step.reward.numpy()\n",
    "    rewards.append(episode_reward)\n",
    "    steps.append(episode_steps)\n",
    "    time_step = tf_env.reset()\n",
    "\n",
    "num_steps = np.sum(steps)\n",
    "avg_length = np.mean(steps)\n",
    "avg_reward = np.mean(rewards)\n",
    "\n",
    "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
    "print('avg_length', avg_length, 'avg_reward:', avg_reward)\n",
    "\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b30b871",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = env\n",
    "eval_py_env = env\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83e25429",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layer_params = (100, 50)\n",
    "action_tensor_spec = tensor_spec.from_spec(env.action_spec())\n",
    "num_actions = action_tensor_spec.maximum - action_tensor_spec.minimum + 1\n",
    "\n",
    "# Define a helper function to create Dense layers configured with the right\n",
    "# activation and kernel initializer.\n",
    "def dense_layer(num_units):\n",
    "  return tf.keras.layers.Dense(\n",
    "      num_units,\n",
    "      activation=tf.keras.activations.relu,\n",
    "      kernel_initializer=tf.keras.initializers.VarianceScaling(\n",
    "          scale=2.0, mode='fan_in', distribution='truncated_normal'))\n",
    "\n",
    "# QNetwork consists of a sequence of Dense layers followed by a dense layer\n",
    "# with `num_actions` units to generate one q_value per available action as\n",
    "# its output.\n",
    "dense_layers = [dense_layer(num_units) for num_units in fc_layer_params]\n",
    "q_values_layer = tf.keras.layers.Dense(\n",
    "    num_actions,\n",
    "    activation=None,\n",
    "    kernel_initializer=tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.03, maxval=0.03),\n",
    "    bias_initializer=tf.keras.initializers.Constant(-0.2))\n",
    "q_net = sequential.Sequential(dense_layers + [q_values_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55e8c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.Variable(0)\n",
    "\n",
    "agent = dqn_agent.DqnAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    q_network=q_net,\n",
    "    optimizer=optimizer,\n",
    "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
    "    train_step_counter=train_step_counter)\n",
    "\n",
    "agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "428ea7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_policy = agent.policy\n",
    "collect_policy = agent.collect_policy\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "409c8d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.8"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics\n",
    "\n",
    "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7738027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/platform/tfrecord_checkpointer.cc:150]  Initializing TFRecordCheckpointer in /tmp/tmpcm5g7ki8.\n",
      "[reverb/cc/platform/tfrecord_checkpointer.cc:386] Loading latest checkpoint from /tmp/tmpcm5g7ki8\n",
      "[reverb/cc/platform/default/server.cc:71] Started replay server on port 21787\n"
     ]
    }
   ],
   "source": [
    "table_name = 'uniform_table'\n",
    "replay_buffer_signature = tensor_spec.from_spec(\n",
    "      agent.collect_data_spec)\n",
    "replay_buffer_signature = tensor_spec.add_outer_dim(\n",
    "    replay_buffer_signature)\n",
    "\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=replay_buffer_max_length,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1),\n",
    "    signature=replay_buffer_signature)\n",
    "\n",
    "reverb_server = reverb.Server([table])\n",
    "\n",
    "replay_buffer = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    agent.collect_data_spec,\n",
    "    table_name=table_name,\n",
    "    sequence_length=2,\n",
    "    local_server=reverb_server)\n",
    "\n",
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "  replay_buffer.py_client,\n",
    "  table_name,\n",
    "  sequence_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d17956e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('step_type',\n",
       " 'observation',\n",
       " 'action',\n",
       " 'policy_info',\n",
       " 'next_step_type',\n",
       " 'reward',\n",
       " 'discount')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.collect_data_spec\n",
    "agent.collect_data_spec._fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fa335ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TimeStep(\n",
       " {'discount': array(1., dtype=float32),\n",
       "  'observation': array([89.52537, 93.8907 , 83.69445, 90.26161], dtype=float32),\n",
       "  'reward': array(0., dtype=float32),\n",
       "  'step_type': array(1, dtype=int32)}),\n",
       " ())"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      random_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=initial_collect_steps).run(train_py_env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "453f1996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f81f01dbc40>\n"
     ]
    }
   ],
   "source": [
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3,\n",
    "    sample_batch_size=batch_size,\n",
    "    num_steps=2).prefetch(3)\n",
    "\n",
    "dataset\n",
    "\n",
    "iterator = iter(dataset)\n",
    "print(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "070fbf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "WARNING:tensorflow:From /home/sgboakes/anaconda3/envs/rl-sat/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:1096: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.foldr(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (30020) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (30020) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (30020) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (30020) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (30020) so Table uniform_table is accessed directly without gRPC.\n",
      "[reverb/cc/client.cc:163] Sampler and server are owned by the same process (30020) so Table uniform_table is accessed directly without gRPC.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 1000: Average Return = 48.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 2000: Average Return = 93.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 3000: Average Return = 9.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 4000: Average Return = 14.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 5000: Average Return = 0.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 6000: Average Return = 88.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 7000: Average Return = 121.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 8000: Average Return = 131.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 9000: Average Return = 63.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 10000: Average Return = 9.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 11000: Average Return = 69.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 12000: Average Return = 35.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 13000: Average Return = 17.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 14000: Average Return = 75.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 15000: Average Return = 228.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 16000: Average Return = 28.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 17000: Average Return = 49.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 18000: Average Return = 165.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 19000: Average Return = 30.0\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "step = 20000: Average Return = 106.0\n"
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "agent.train = common.function(agent.train)\n",
    "\n",
    "# Reset the train step.\n",
    "agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "# Reset the environment.\n",
    "time_step = train_py_env.reset()\n",
    "\n",
    "# Create a driver to collect experience.\n",
    "collect_driver = py_driver.PyDriver(\n",
    "    env,\n",
    "    py_tf_eager_policy.PyTFEagerPolicy(\n",
    "      agent.collect_policy, use_tf_function=True),\n",
    "    [rb_observer],\n",
    "    max_steps=collect_steps_per_iteration)\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps and save to the replay buffer.\n",
    "  time_step, _ = collect_driver.run(time_step)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = agent.train(experience).loss\n",
    "\n",
    "  step = agent.train_step_counter.numpy()\n",
    "\n",
    "#   if step % log_interval == 0:\n",
    "#     print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f9a7f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Iterations')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "\n",
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "# plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab19112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
